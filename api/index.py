# Force redeployment by adding a comment
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Depends, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, RedirectResponse, FileResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel
import requests
import google.generativeai as genai
import os
from dotenv import load_dotenv
import re
from typing import Optional, List
from datetime import datetime, timedelta
import pathlib
import jwt
import secrets
import asyncio
from fastapi import BackgroundTasks

# í˜„ì¬ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = pathlib.Path(__file__).resolve().parent.parent  # api í´ë”ì˜ ìƒìœ„ í´ë”
FRONTEND_DIR = BASE_DIR / "frontend"

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = FastAPI(title="IR Analyzer", version="1.0.0")

# JWT ì„¤ì •
JWT_SECRET_KEY = os.getenv("JWT_SECRET_KEY", secrets.token_urlsafe(32))
JWT_ALGORITHM = "HS256"
JWT_ACCESS_TOKEN_EXPIRE_HOURS = 24

# Security scheme
security = HTTPBearer(auto_error=False)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ - public í´ë” ì‚¬ìš©
PUBLIC_DIR = BASE_DIR / "public"
try:
    if (PUBLIC_DIR / "static").exists():
        app.mount("/static", StaticFiles(directory=PUBLIC_DIR / "static"), name="static")
    else:
        print(f"âš ï¸ Static directory not found: {PUBLIC_DIR / 'static'}")
except Exception as e:
    print(f"âš ï¸ Failed to mount static files: {e}")

# JSON ë°ì´í„° íŒŒì¼ ì„œë¹™ì„ ìœ„í•œ ë£¨íŠ¸ ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸

@app.get("/")
async def get_homepage():
    """ë©”ì¸ í™ˆí˜ì´ì§€ ë°˜í™˜"""
    try:
        index_path = PUBLIC_DIR / "index.html"
        if index_path.exists():
            return FileResponse(index_path, media_type="text/html")
        else:
            return HTMLResponse(content="""
            <html><head><title>IR Analyzer</title></head>
            <body><h1>IR Analyzer</h1><p>Investment Report Analysis Platform</p></body>
            </html>
            """)
    except Exception as e:
        return HTMLResponse(content=f"<h1>Error loading homepage: {str(e)}</h1>", status_code=500)

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ìš© ê°„ë‹¨í•œ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "message": "IR Analyzer is running"}

@app.get("/impact-report-data.json")
async def get_impact_report_data():
    """ì„íŒ©íŠ¸ ë¦¬í¬íŠ¸ ë°ëª¨ ë°ì´í„° ë°˜í™˜"""
    json_path = BASE_DIR / "impact-report-data.json"
    if json_path.exists():
        return FileResponse(json_path, media_type="application/json")
    else:
        raise HTTPException(status_code=404, detail="Demo data not found")


# Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ìš”ì²­ ëª¨ë¸
class IRAnalysisRequest(BaseModel):
    company_name: str
    ir_url: str
    analysis_type: Optional[str] = "investment_report"

class JandiWebhookRequest(BaseModel):
    text: str
    writer_name: Optional[str] = "Unknown"

class LoginRequest(BaseModel):
    api_key: str

class TokenResponse(BaseModel):
    access_token: str
    token_type: str
    expires_in: int

# Vercel Blob ê´€ë ¨ ëª¨ë¸ë“¤
class BlobUploadRequest(BaseModel):
    company_name: str
    analysis_type: Optional[str] = "investment_report"

class BlobUploadResponse(BaseModel):
    success: bool
    job_id: str
    message: str
    upload_url: Optional[str] = None
    
class BlobAnalysisStatus(BaseModel):
    job_id: str
    status: str  # 'pending', 'processing', 'completed', 'failed'
    progress: int
    message: str
    result: Optional[dict] = None
    error: Optional[str] = None

# JWT í† í° ìƒì„± í•¨ìˆ˜
def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(hours=JWT_ACCESS_TOKEN_EXPIRE_HOURS)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)
    return encoded_jwt

# JWT í† í° ê²€ì¦ í•¨ìˆ˜
def verify_token(credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)):
    if not credentials:
        raise HTTPException(
            status_code=401,
            detail="ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.",
            headers={"WWW-Authenticate": "Bearer"},
        )
    
    try:
        payload = jwt.decode(credentials.credentials, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
        api_key: str = payload.get("api_key")
        if api_key is None:
            raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ í† í°ì…ë‹ˆë‹¤.")
        return api_key
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="í† í°ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.")
    except jwt.JWTError:
        raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šì€ í† í°ì…ë‹ˆë‹¤.")

# Gemini API í‚¤ ê²€ì¦ í•¨ìˆ˜
def verify_gemini_api_key(api_key: str) -> bool:
    # ê°œë°œ ëª¨ë“œì—ì„œëŠ” í…ŒìŠ¤íŠ¸ í‚¤ í—ˆìš©
    if os.getenv("ENVIRONMENT") == "development" and api_key == "test_gemini_api_key_for_development":
        print("[DEV MODE] Using test API key")
        return True
    
    try:
        # ì„ì‹œë¡œ Gemini API ì„¤ì •í•˜ì—¬ ìœ íš¨ì„± ê²€ì¦
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ìš”ì²­
        response = model.generate_content("Hello")
        return True
    except Exception as e:
        print(f"API í‚¤ ê²€ì¦ ì‹¤íŒ¨: {str(e)}")
        return False

@app.get("/", response_class=HTMLResponse)
async def get_homepage():
    """ë©”ì¸ í™ˆí˜ì´ì§€ ë°˜í™˜"""
    index_path = PUBLIC_DIR / "index.html"
    if not index_path.is_file():
        return HTMLResponse(content="<h1>Frontend file not found</h1>", status_code=404)
    return HTMLResponse(content=index_path.read_text(encoding="utf-8"))

@app.get("/login", response_class=HTMLResponse)
async def get_login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€ ë°˜í™˜"""
    html_path = PUBLIC_DIR / "login.html"
    if html_path.exists():
        return FileResponse(html_path, media_type="text/html")
    else:
        return HTMLResponse("<h1>Login</h1><p>Login page not found</p>")

@app.post("/api/login", response_model=TokenResponse)
async def login(request: LoginRequest):
    """API í‚¤ë¡œ ë¡œê·¸ì¸í•˜ì—¬ JWT í† í° ë°œê¸‰"""
    try:
        # Gemini API í‚¤ ìœ íš¨ì„± ê²€ì¦
        if not verify_gemini_api_key(request.api_key):
            raise HTTPException(
                status_code=401, 
                detail="ìœ íš¨í•˜ì§€ ì•Šì€ Gemini API í‚¤ì…ë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        # JWT í† í° ìƒì„±
        access_token = create_access_token(
            data={"api_key": request.api_key, "sub": "user"}
        )
        
        return TokenResponse(
            access_token=access_token,
            token_type="bearer",
            expires_in=JWT_ACCESS_TOKEN_EXPIRE_HOURS * 3600  # ì´ˆ ë‹¨ìœ„
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"ë¡œê·¸ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail="ë¡œê·¸ì¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.post("/api/logout")
async def logout():
    """ë¡œê·¸ì•„ì›ƒ (í´ë¼ì´ì–¸íŠ¸ì—ì„œ í† í° ì‚­ì œ)"""
    return {"message": "ë¡œê·¸ì•„ì›ƒë˜ì—ˆìŠµë‹ˆë‹¤. í† í°ì„ ì‚­ì œí•´ì£¼ì„¸ìš”."}

class TheoryOfChangeRequest(BaseModel):
    organization_name: str
    impact_focus: Optional[str] = None

@app.post("/api/generate-theory-of-change")
async def generate_theory_of_change(
    request: TheoryOfChangeRequest,
    api_key: str = Depends(verify_token)
):
    """ë³€í™”ì´ë¡ (Theory of Change) ë™ì  ìƒì„± API"""
    try:
        print(f"ğŸ¯ ë³€í™”ì´ë¡  ìƒì„± ìš”ì²­: {request.organization_name}")
        
        # theory_of_change ëª¨ë“ˆ import
        import sys
        sys.path.append(str(BASE_DIR))  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
        from theory_of_change import TheoryOfChangeOrchestrator
        
        # ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì´ˆê¸°í™” ë° ì‹¤í–‰
        orchestrator = TheoryOfChangeOrchestrator(api_key)
        theory_data = await orchestrator.generate_theory_of_change(
            organization_name=request.organization_name,
            impact_focus=request.impact_focus
        )
        
        print(f"âœ… ë³€í™”ì´ë¡  ìƒì„± ì™„ë£Œ: {request.organization_name}")
        
        return {
            "success": True,
            "organization_name": request.organization_name,
            "theory_data": theory_data,
            "generated_by": "multi-agent-system",
            "agents_used": [
                "context-analyzer", "user-insight", "strategy-designer", 
                "validator", "storyteller"
            ],
            "generated_at": datetime.now().isoformat(),
            "message": "ë³€í™”ì´ë¡ ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        print(f"âŒ ë³€í™”ì´ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë³€í™”ì´ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ===== VERCEL BLOB í†µí•© API ì—”ë“œí¬ì¸íŠ¸ë“¤ =====

# ê¸€ë¡œë²Œ ì‘ì—… ìƒíƒœ ì €ì¥ì†Œ (ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” Redis ë“± ì‚¬ìš©)
job_storage = {}


# === TEST ENDPOINT FOR DEBUGGING ===
@app.post("/api/test/upload")
async def test_upload_endpoint(
    files: List[UploadFile] = File(...),
    company_name: str = Form(...),
    api_key: str = Depends(verify_token)
):
    """Simple test endpoint to isolate 500 error"""
    try:
        print(f"[TEST] Received {len(files)} files for {company_name}")
        
        file_info = []
        for file in files:
            file_info.append({
                "filename": file.filename,
                "content_type": file.content_type,
                "size": len(await file.read()) if hasattr(file, 'read') else 0
            })
            # Reset file pointer if we read it
            if hasattr(file, 'seek'):
                await file.seek(0)
        
        return {
            "success": True,
            "message": f"Test successful - received {len(files)} files",
            "files": file_info,
            "company_name": company_name
        }
        
    except Exception as e:
        print(f"[ERROR] Test endpoint failed: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Test endpoint error: {str(e)}")

@app.post("/api/debug/upload")
async def debug_upload_endpoint(
    files: List[UploadFile] = File(...),
    company_name: str = Form(...)
):
    """
    BRAND NEW ENDPOINT FOR DEBUGGING
    """
    print(f"[DEBUG] New debug endpoint called")
    print(f"[DEBUG] Company: {company_name}")
    print(f"[DEBUG] Files: {len(files)}")
    
    return {
        "success": True,
        "message": "New debug endpoint works!"
    }

@app.post("/api/blob/upload")
async def blob_upload_endpoint(
    files: List[UploadFile] = File(...),
    company_name: str = Form(...)
):
    """
    ULTRA SIMPLIFIED FOR DEBUGGING - No dependencies, no response model
    """
    try:
        print(f"[DEBUG] Ultra simplified endpoint called")
        print(f"[DEBUG] Company: {company_name}")
        print(f"[DEBUG] Files: {len(files)}")
        
        return {
            "success": True,
            "job_id": "test-job-id", 
            "message": "Ultra simplified test successful"
        }
        
    except Exception as e:
        print(f"[ERROR] Ultra simplified endpoint failed: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"error": str(e)}

@app.get("/api/blob/status/{job_id}", response_model=BlobAnalysisStatus)
async def get_blob_job_status(job_id: str):
    """
    ì‘ì—… ìƒíƒœ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
    
    ì‹¤ì‹œê°„ ì§„í–‰ë¥ ê³¼ ìƒíƒœë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    if job_id not in job_storage:
        raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    job_data = job_storage[job_id]
    
    return BlobAnalysisStatus(
        job_id=job_id,
        status=job_data["status"],
        progress=job_data["progress"],
        message=job_data["message"],
        result=job_data.get("result"),
        error=job_data.get("error")
    )

async def process_blob_files_background(
    job_id: str, 
    files: List[UploadFile], 
    company_name: str, 
    api_key: str
):
    """
    ë°±ê·¸ë¼ìš´ë“œì—ì„œ Blob íŒŒì¼ ì²˜ë¦¬
    
    ì§„í–‰ë¥ ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ë©° ì‚¬ìš©ì ì¹œí™”ì ì¸ í”¼ë“œë°± ì œê³µ
    """
    try:
        import sys
        sys.path.append(str(BASE_DIR))
        from blob_processor import blob_processor
        
        def update_progress(stage: str, progress: int, message: str):
            """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°±"""
            job_storage[job_id].update({
                "status": "processing",
                "progress": progress,
                "message": message,
                "stage": stage
            })
            print(f"[PROGRESS] [{job_id}] {stage}: {progress}% - {message}")
        
        # 1ë‹¨ê³„: íŒŒì¼ ê²€ì¦ ë° Blob ì—…ë¡œë“œ
        update_progress("validation", 5, "íŒŒì¼ ê²€ì¦ ì¤‘...")
        
        blob_urls = []
        total_files = len(files)
        
        for i, file in enumerate(files):
            file_progress_base = (i / total_files) * 40  # ì—…ë¡œë“œëŠ” ì „ì²´ì˜ 40%
            
            # íŒŒì¼ ë°ì´í„° ì½ê¸°
            file_content = await file.read()
            
            update_progress(
                "blob-upload", 
                int(file_progress_base + 5), 
                f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘... ({i+1}/{total_files}) {file.filename}"
            )
            
            # Vercel Blobì— ì—…ë¡œë“œ
            upload_result = await blob_processor.upload_to_blob(
                file_content, 
                file.filename,
                lambda stage, prog, msg: update_progress(
                    stage, 
                    int(file_progress_base + (prog * 0.35)), 
                    f"{msg} ({i+1}/{total_files})"
                )
            )
            
            if upload_result["success"]:
                blob_urls.append({
                    "blob_url": upload_result["blob_url"],
                    "filename": file.filename,
                    "metadata": upload_result["metadata"]
                })
                print(f"[SUCCESS] [{job_id}] Blob ì—…ë¡œë“œ ì„±ê³µ: {file.filename}")
            else:
                raise Exception(f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {file.filename} - {upload_result['error']}")
        
        # 2ë‹¨ê³„: íŒŒì¼ ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        update_progress("file-processing", 45, "íŒŒì¼ ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        combined_content = []
        for i, blob_info in enumerate(blob_urls):
            file_progress_base = 45 + (i / total_files) * 30  # ì²˜ë¦¬ëŠ” 30%
            
            update_progress(
                "file-processing",
                int(file_progress_base),
                f"íŒŒì¼ ë¶„ì„ ì¤‘... ({i+1}/{total_files}) {blob_info['filename']}"
            )
            
            # Blobì—ì„œ íŒŒì¼ ì²˜ë¦¬
            ir_summary = await blob_processor.process_blob_file(
                blob_info["blob_url"],
                blob_info["filename"],
                lambda stage, prog, msg: update_progress(
                    stage,
                    int(file_progress_base + (prog * 0.3)),
                    f"{msg} ({i+1}/{total_files})"
                )
            )
            
            combined_content.append(f"=== {blob_info['filename']} ===\n{ir_summary}\n")
        
        # 3ë‹¨ê³„: AI ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
        update_progress("ai-analysis", 75, "AIê°€ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
        
        combined_ir_summary = "\n".join(combined_content)
        
        # íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©)
        if os.getenv("ENVIRONMENT") == "development" and api_key == "test_gemini_api_key_for_development":
            # ê°œë°œ ëª¨ë“œì—ì„œëŠ” Mock íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„±
            investment_report = f"""
# Mock íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ - {company_name}

## Executive Summary

**íˆ¬ì ë…¼ì§€**: {company_name}ëŠ” í˜ì‹ ì ì¸ ê¸°ìˆ ê³¼ ê°•ë ¥í•œ ì‹œì¥ í¬ì§€ì…˜ì„ í†µí•´ ì§€ì† ê°€ëŠ¥í•œ ì„±ì¥ì„ ì‹¤í˜„í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.

## 1. íˆ¬ì ê°œìš”

### 1.1. ê¸°ì—… ê°œìš”
- **íšŒì‚¬ëª…**: {company_name}
- **ì‚¬ì—… ë¶„ì•¼**: Mock IR ë¶„ì„ ê¸°ë°˜
- **ì„¤ë¦½ë…„ë„**: 2020ë…„ (ì¶”ì •)

### 1.2. íˆ¬ì ì¡°ê±´
- **íˆ¬ì ê¸ˆì•¡**: 10ì–µì› (ì œì•ˆ)
- **ì§€ë¶„ìœ¨**: 15%
- **íˆ¬ì í˜•íƒœ**: ì‹œë¦¬ì¦ˆ A

### 1.3. ì†ìµ ì¶”ì • ë° ìˆ˜ìµì„±
- **ì˜ˆìƒ ë§¤ì¶œ (2025)**: 50ì–µì›
- **ì˜ˆìƒ EBITDA**: 10ì–µì›
- **IRR**: 25% (ì¶”ì •)

## 2. ê¸°ì—… í˜„í™©

Mock ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•œ ê²°ê³¼, í•´ë‹¹ ê¸°ì—…ì€ ì•ˆì •ì ì¸ ì„±ì¥ ê¶¤ë„ì— ìˆìŠµë‹ˆë‹¤.

## 7. ì¢…í•© ê²°ë¡ 

**íˆ¬ì ê¶Œê³ **: ì ê·¹ ê²€í†  ê¶Œì¥

ìœ„ì™€ ê°™ì€ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ, {company_name}ì— ëŒ€í•œ íˆ¬ìë¥¼ ê¸ì •ì ìœ¼ë¡œ ê²€í† í•  ê²ƒì„ ì œì•ˆí•©ë‹ˆë‹¤.

---
*ì´ ë³´ê³ ì„œëŠ” ê°œë°œ ëª¨ë“œì—ì„œ ìƒì„±ëœ Mock ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.*
"""
        else:
            investment_report = await generate_investment_report(
                ir_summary=combined_ir_summary,
                company_name=company_name,
                api_key=api_key
            )
        
        # 4ë‹¨ê³„: ì™„ë£Œ
        update_progress("completed", 100, "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ! ğŸ‰")
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        job_storage[job_id].update({
            "status": "completed",
            "progress": 100,
            "message": "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!",
            "result": {
                "company_name": company_name,
                "investment_report": investment_report,
                "source_files": [blob_info["filename"] for blob_info in blob_urls],
                "blob_info": blob_urls,
                "file_count": len(files),
                "report_type": "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ì´ˆì•ˆ (Vercel Blob)",
                "completed_at": datetime.now().isoformat()
            }
        })
        
        print(f"ğŸ‰ [{job_id}] Blob íŒŒì¼ ì²˜ë¦¬ ì™„ì „ ì™„ë£Œ!")
        
        # ì„ íƒì‚¬í•­: Blob ì •ë¦¬ (24ì‹œê°„ í›„ ìë™ ì‚­ì œ ë“±)
        # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©
        
    except Exception as e:
        print(f"[ERROR] [{job_id}] Blob ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        
        job_storage[job_id].update({
            "status": "failed",
            "progress": 0,
            "message": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "error": str(e)
        })

@app.post("/api/analyze-ir-files")
async def analyze_ir_files(
    files: List[UploadFile] = File(...),
    company_name: str = Form(...),
    api_key: str = Depends(verify_token)
):
    """ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•œ IR ìë£Œ ë¶„ì„"""
    try:
        print(f"ğŸ“ ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„ ì‹œì‘: {company_name} - {len(files)}ê°œ íŒŒì¼")
        
        # ì…ë ¥ ë°ì´í„° ê²€ì¦ ë¡œê¹…
        print(f"ğŸ” Request validation - Company: {company_name}, Files count: {len(files)}")
        for i, file in enumerate(files):
            print(f"  File {i+1}: {file.filename}, Content-Type: {file.content_type}")
        
        # ë¹ˆ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ê²€ì¦
        if not files or len(files) == 0:
            raise HTTPException(status_code=400, detail="ì—…ë¡œë“œí•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        # company_name ê²€ì¦
        if not company_name or company_name.strip() == "":
            raise HTTPException(status_code=400, detail="íšŒì‚¬ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        combined_content = []
        total_size = 0
        
        for file in files:
            # íŒŒì¼ëª… ì¡´ì¬ ê²€ì¦
            if not file.filename:
                raise HTTPException(status_code=400, detail="íŒŒì¼ëª…ì´ ì—†ëŠ” íŒŒì¼ì´ ìˆìŠµë‹ˆë‹¤.")
            
            # íŒŒì¼ í˜•ì‹ ê²€ì¦
            if not file.filename.lower().endswith(('.pdf', '.xlsx', '.xls', '.docx', '.doc')):
                print(f"[ERROR] ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file.filename}")
                raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file.filename}. ì§€ì› í˜•ì‹: PDF, Excel, Word")
            
            # ê°œë³„ íŒŒì¼ í¬ê¸° í™•ì¸
            file_content = await file.read()
            file_size = len(file_content)
            total_size += file_size
            
            print(f"ğŸ“„ íŒŒì¼ ì½ê¸° ì™„ë£Œ: {file.filename} ({file_size:,} bytes)")
            
            # ë¹ˆ íŒŒì¼ ê²€ì¦
            if file_size == 0:
                raise HTTPException(status_code=400, detail=f"ë¹ˆ íŒŒì¼ì…ë‹ˆë‹¤: {file.filename}")
            
            # ê°œë³„ íŒŒì¼ í¬ê¸° ì œí•œ (4.5MB)
            if file_size > 4.5 * 1024 * 1024:
                raise HTTPException(status_code=400, detail=f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤: {file.filename} ({file_size:,} bytes). ìµœëŒ€ 4.5MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤.")
            
            # íŒŒì¼ ì²˜ë¦¬
            ir_summary = await process_uploaded_file(file_content, file.filename)
            combined_content.append(f"=== {file.filename} ===\n{ir_summary}\n")
            print(f"ğŸ“„ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {file.filename}")
        
        # ì „ì²´ íŒŒì¼ í¬ê¸° ê²€ì¦ (4.5MB ì œí•œ - Vercel ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ ìµœì í™”)
        print(f"[INFO] ì „ì²´ íŒŒì¼ í¬ê¸°: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)")
        if total_size > 4.5 * 1024 * 1024:
            raise HTTPException(status_code=400, detail=f"ì „ì²´ íŒŒì¼ í¬ê¸°ê°€ ì œí•œì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤: {total_size:,} bytes. ìµœëŒ€ 4.5MBê¹Œì§€ í—ˆìš©ë©ë‹ˆë‹¤.")
        
        # ëª¨ë“  íŒŒì¼ ë‚´ìš©ì„ ê²°í•©
        combined_ir_summary = "\n".join(combined_content)
        
        # íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„±
        investment_report = await generate_investment_report(
            ir_summary=combined_ir_summary,
            company_name=company_name,
            api_key=api_key
        )
        print(f"ğŸ“‹ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        return {
            "success": True,
            "company_name": company_name,
            "investment_report": investment_report,
            "source_files": [file.filename for file in files],
            "file_count": len(files),
            "report_type": "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ì´ˆì•ˆ (ë‹¤ì¤‘ íŒŒì¼)"
        }
        
    except HTTPException as he:
        print(f"[ERROR] HTTP ê²€ì¦ ì˜¤ë¥˜ (400): {he.detail}")
        raise
    except Exception as e:
        print(f"[ERROR] ë‹¤ì¤‘ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ë‹¤ì¤‘ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/api/analyze-ir-file")
async def analyze_ir_file(
    file: UploadFile = File(...),
    company_name: str = Form(...),
    api_key: str = Depends(verify_token)
):
    """íŒŒì¼ ì—…ë¡œë“œë¥¼ í†µí•œ IR ìë£Œ ë¶„ì„"""
    try:
        print(f"ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ë¶„ì„ ì‹œì‘: {company_name} - {file.filename}")
        
        # íŒŒì¼ ê²€ì¦
        if not file.filename.lower().endswith(('.pdf', '.xlsx', '.xls', '.docx', '.doc')):
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦ (4.5MB ì œí•œ - Vercel ì„œë²„ë¦¬ìŠ¤ í•¨ìˆ˜ ìµœì í™”)
        file_content = await file.read()
        if len(file_content) > 4.5 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="íŒŒì¼ í¬ê¸°ëŠ” 4.5MBë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•ˆì •ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì œí•œì‚¬í•­ì…ë‹ˆë‹¤.")
        
        # íŒŒì¼ ì²˜ë¦¬
        ir_summary = await process_uploaded_file(file_content, file.filename)
        print(f"ğŸ“„ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {file.filename}")
        
        # íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„±
        investment_report = await generate_investment_report(
            ir_summary=ir_summary,
            company_name=company_name,
            api_key=api_key
        )
        print(f"ğŸ“‹ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        return {
            "success": True,
            "company_name": company_name,
            "investment_report": investment_report,
            "source_file": file.filename,
            "report_type": "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ì´ˆì•ˆ"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

async def process_uploaded_file(file_content: bytes, filename: str) -> str:
    """ì—…ë¡œë“œëœ íŒŒì¼ ì²˜ë¦¬"""
    try:
        import sys
        sys.path.append(str(BASE_DIR))  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
        from pdf_processor import PDFProcessor
        
        processor = PDFProcessor()
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ì²˜ë¦¬
        file_ext = filename.lower().split('.')[-1]
        
        if file_ext == 'pdf':
            # PDF ì²˜ë¦¬
            pdf_result = processor.extract_text_from_bytes(file_content)
            
            if pdf_result["success"]:
                # ê°€ìƒì˜ URLë¡œ summary ìƒì„±
                extracted_data = {
                    "success": True,
                    "url": f"uploaded_file://{filename}",
                    "file_size": len(file_content),
                    "extracted_text": pdf_result["text"],
                    "page_count": pdf_result["page_count"],
                    "company_info": processor.extract_company_info(pdf_result["text"])
                }
                return processor.create_ir_summary(extracted_data)
            else:
                raise Exception(f"PDF ì²˜ë¦¬ ì‹¤íŒ¨: {pdf_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        elif file_ext in ['xlsx', 'xls']:
            # Excel ì²˜ë¦¬ (ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
            return f"""
=== IR ìë£Œ ë¶„ì„ ì›ë³¸ ë°ì´í„° ===

ğŸ“Š íŒŒì¼ ì •ë³´:
- íŒŒì¼ëª…: {filename}
- íŒŒì¼ í¬ê¸°: {len(file_content):,} bytes
- íŒŒì¼ í˜•ì‹: Excel

ğŸ“„ íŒŒì¼ ë‚´ìš©:
Excel íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. 
íŒŒì¼ ì²˜ë¦¬ ê¸°ëŠ¥ì„ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤.

=== ë¶„ì„ ìš”ì²­ ===
ìœ„ì˜ IR ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        elif file_ext in ['docx', 'doc']:
            # Word ì²˜ë¦¬ (ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
            return f"""
=== IR ìë£Œ ë¶„ì„ ì›ë³¸ ë°ì´í„° ===

ğŸ“Š íŒŒì¼ ì •ë³´:
- íŒŒì¼ëª…: {filename}
- íŒŒì¼ í¬ê¸°: {len(file_content):,} bytes
- íŒŒì¼ í˜•ì‹: Word

ğŸ“„ íŒŒì¼ ë‚´ìš©:
Word íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.
íŒŒì¼ ì²˜ë¦¬ ê¸°ëŠ¥ì„ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤.

=== ë¶„ì„ ìš”ì²­ ===
ìœ„ì˜ IR ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        else:
            raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {file_ext}")
            
    except Exception as e:
        raise Exception(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")


@app.post("/api/analyze-ir")
async def analyze_ir(request: IRAnalysisRequest, api_key: str = Depends(verify_token)):
    """IR ìë£Œ ë¶„ì„ ë©”ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        print(f"ğŸ“Š IR ë¶„ì„ ì‹œì‘: {request.company_name}")
        
        # 1. IR íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ir_summary = await download_and_extract_ir(request.ir_url)
        print(f"ğŸ“„ IR íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
        
        # 2. JSONL í•™ìŠµ ë°ì´í„°ì™€ í•¨ê»˜ Gemini APIë¡œ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„±
        investment_report = await generate_investment_report(
            ir_summary=ir_summary,
            company_name=request.company_name,
            api_key=api_key
        )
        print(f"ğŸ“‹ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
        
        # 3. ê²°ê³¼ë¥¼ ì—¬ëŸ¬ ê³³ì— ì „ë‹¬
        await distribute_results({
            "company_name": request.company_name,
            "investment_report": investment_report,
            "source_url": request.ir_url,
            "analysis_date": datetime.now().isoformat(),
            "requester": "API"
        })
        
        return {
            "success": True,
            "company_name": request.company_name,
            "investment_report": investment_report,
            "source_url": request.ir_url,
            "report_type": "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ì´ˆì•ˆ",
            "message": "ë³´ê³ ì„œê°€ ìƒì„±ë˜ì–´ Airtable, ì´ë©”ì¼ ë“±ìœ¼ë¡œ ì „ë‹¬ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/webhook/jandi")
async def jandi_webhook(request: JandiWebhookRequest):
    """ì”ë”” ì›¹í›… ì²˜ë¦¬"""
    try:
        print(f"ğŸ“ ì”ë”” ì›¹í›… ìˆ˜ì‹ : {request.text}")
        
        # ë©”ì‹œì§€ì—ì„œ URLê³¼ íšŒì‚¬ëª… ì¶”ì¶œ
        url_pattern = r'https?://[^\s]+\.(?:pdf|xlsx?|docx?)'
        urls = re.findall(url_pattern, request.text, re.IGNORECASE)
        
        if not urls:
            return {"success": False, "message": "IR ìë£Œ URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        # íšŒì‚¬ëª… ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
        company_name = extract_company_name(request.text)
        
        # IR ë¶„ì„ ì‹¤í–‰
        analysis_request = IRAnalysisRequest(
            company_name=company_name,
            ir_url=urls[0]
        )
        
        result = await analyze_ir(analysis_request)
        
        return {
            "success": True,
            "message": f"{company_name} IR ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "result": result
        }
        
    except Exception as e:
        print(f"âŒ ì”ë”” ì›¹í›… ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
        return {"success": False, "message": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

async def download_and_extract_ir(url: str) -> str:
    """IR íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        import sys
        sys.path.append(str(BASE_DIR))  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
        from pdf_processor import PDFProcessor
        
        print(f"ğŸ“¥ PDF ì²˜ë¦¬ ì‹œì‘: {url}")
        processor = PDFProcessor()
        result = processor.extract_text_from_url(url)
        
        if result["success"]:
            print(f"âœ… PDF ì²˜ë¦¬ ì„±ê³µ: {result['page_count']}í˜ì´ì§€, {len(result['extracted_text'])}ê¸€ì")
            return processor.create_ir_summary(result)
        else:
            raise Exception(result["error"])
            
    except Exception as e:
        raise Exception(f"íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

async def generate_investment_report(ir_summary: str, company_name: str, api_key: str) -> str:
    """JSONL í•™ìŠµ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„±"""
    try:
        import sys
        sys.path.append(str(BASE_DIR))  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
        from jsonl_processor import JSONLProcessor
        
        print(f"ğŸ“š JSONL í•™ìŠµ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # JSONL í•™ìŠµ ë°ì´í„° ë¡œë“œ (api í´ë” ë‚´ ê²½ë¡œ ì§€ì •)
        jsonl_path = BASE_DIR / "jsonl_data"
        processor = JSONLProcessor(str(jsonl_path))
        learning_context = processor.create_learning_context()
        report_template = processor.get_report_structure_template()
        
        print(f"ğŸ“– í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(processor.learned_reports)}ê°œ ë³´ê³ ì„œ")
        
        # íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± í”„ë¡¬í”„íŠ¸ (ë¨¸ì‰¬ì•¤ ìŠ¤íƒ€ì¼ ê¸°ë°˜)
        prompt = f"""
MISSION (ìµœì¢… ì„ë¬´)
ë‹¹ì‹ ì€ í•œ ëª…ì˜ ì‹¬ì‚¬ì—­ì´ ì•„ë‹Œ, **ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ì„íŒ©íŠ¸ íˆ¬ìì‚¬ë¥¼ ì´ë„ëŠ” ë§¤ë‹ˆì§• íŒŒíŠ¸ë„ˆ(Managing Partner)**ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ í•œë§ˆë””ëŠ” íˆ¬ìì˜ ë°©í–¥ì„ ê²°ì •í•˜ê³ , ë‹¹ì‹ ì˜ íˆ¬ì ë©”ëª¨ëŠ” ë‹¨ìˆœí•œ ë³´ê³ ì„œê°€ ì•„ë‹Œ, **í•˜ë‚˜ì˜ ì‚°ì—…ì„ ì •ì˜í•˜ê³  íšŒì‚¬ì˜ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” 'ì„ ì–¸ë¬¸(Manifesto)'**ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‚ ì¹´ë¡œìš´ í†µì°°ë ¥ê³¼ ì••ë„ì ì¸ ë…¼ë¦¬ë¡œ, íŒŒíŠ¸ë„ˆ íšŒì˜ì—ì„œ ë°˜ë¡ ì˜ ì—¬ì§€ ì—†ì´ íˆ¬ìë¥¼ ê´€ì² ì‹œí‚¤ëŠ” **'Investment Thesis Memo'**ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  ë¬¸ì¥ì€ ë‹¹ì‹ ì˜ í™•ì‹ ì„ ì¦ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

THE PARTNER'S DECALOGUE (íŒŒíŠ¸ë„ˆì˜ 10ê³„ëª…)
ë‹¹ì‹ ì€ ë³´ê³ ì„œ ì‘ì„± ì‹œ, ì•„ë˜ 10ê°€ì§€ ì›ì¹™ì„ 'ì‹ ì¡°'ì²˜ëŸ¼ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.

1. ëª¨ë“  ê²ƒì€ 'íˆ¬ì ë…¼ì§€(Investment Thesis)'ì—ì„œ ì‹œì‘ëœë‹¤.

ë³´ê³ ì„œ ì„œë‘ì— ì´ íˆ¬ì ê±´ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ì˜í•˜ëŠ”, ê°•ë ¥í•˜ê³  ëª…ë£Œí•œ 'íˆ¬ì ë…¼ì§€'ë¥¼ ì„ ì–¸í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ë™ì‚¬ëŠ” í­ë°œí•˜ëŠ” ëŒ€ì²´ì‹í’ˆ ì‹œì¥ì˜ 'Intel Inside'ê°€ ë  ê²ƒì´ë©°, ëª¨ë“  ì‹í’ˆ ëŒ€ê¸°ì—…ì´ ì˜ì¡´í•  ìˆ˜ë°–ì— ì—†ëŠ” ê³ ë¶€ê°€ê°€ì¹˜ ì›ì²œì†Œì¬ ê³µê¸‰ë§ì„ ë…ì í•  ê²ƒì…ë‹ˆë‹¤.")

ë³´ê³ ì„œì˜ ëª¨ë“  ë‚´ìš©(ì‹œì¥, íŒ€, ê¸°ìˆ , ì¬ë¬´)ì€ ì´ í•µì‹¬ ë…¼ì§€ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•œ ê·¼ê±°ë¡œë§Œ ê¸°ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

2. ëª¨ë“  ì£¼ì¥ì€ ìˆ«ìë¡œ ë§í•œë‹¤ (Quant-First Mandate).

"ì‹œì¥ì´ í¬ë‹¤"ê°€ ì•„ë‹ˆë¼, "ì—°í‰ê·  18.6%ë¡œ ì„±ì¥í•˜ì—¬ 2030ë…„ 162ì¡°ì›ì— ë‹¬í•˜ëŠ” ì‹œì¥"ìœ¼ë¡œ ì„œìˆ í•©ë‹ˆë‹¤.

"íŒ€ì´ ìš°ìˆ˜í•˜ë‹¤"ê°€ ì•„ë‹ˆë¼, "ì´í•© 20ë…„ ì´ìƒì˜ ë²„ì„¯ ì—°êµ¬ ê²½ë ¥ê³¼ KAIST MBAì˜ ì‚¬ì—… ì „ëµì„ ê²°í•©í•œ íŒ€"ìœ¼ë¡œ ê³„ëŸ‰í™”í•©ë‹ˆë‹¤.

3. 'íšŒì‚¬ì˜ ì£¼ì¥'ê³¼ 'ë‚˜ì˜ ê´€ì 'ì„ ëª…í™•íˆ ë¶„ë¦¬í•œë‹¤ (The Analyst's Edge).

ì¬ë¬´ ì¶”ì • ë“±ì—ì„œ íšŒì‚¬ ì œì‹œ ìë£Œ(Company-provided)ì™€ ì‹¬ì‚¬ì—­ ì¶”ì •(Analyst's View)ì„ ë°˜ë“œì‹œ ë¶„ë¦¬í•˜ì—¬ ì œì‹œí•˜ì‹­ì‹œì˜¤.

ë‚˜ì˜ ê´€ì ì—ì„œ ë³´ìˆ˜ì ì¸ ê°€ì •ì„ ì ìš©í–ˆë‹¤ë©´(ì˜ˆ: "íšŒì‚¬ ì œì‹œ ë§¤ì¶œì˜ 50% ìˆ˜ì¤€ìœ¼ë¡œ í• ì¸ ì ìš©"), ê·¸ ë…¼ë¦¬ì  ê·¼ê±°(ì‹œì¥ ê²½ìŸ ì‹¬í™” ê°€ëŠ¥ì„±, ì´ˆê¸° ì‹œì¥ì˜ ë¶ˆí™•ì‹¤ì„± ë“±)ë¥¼ ëª…í™•íˆ ë°íˆì‹­ì‹œì˜¤.

4. ìŠ¤ìŠ¤ë¡œ íˆ¬ìë¥¼ ê¸°ê°ì‹œì¼œë¼ (Investment Killer Analysis).

ë¦¬ìŠ¤í¬ ë¶„ì„ì„ ë„˜ì–´, 'ì´ íˆ¬ìê°€ ì‹¤íŒ¨í•  ìˆ˜ë°–ì— ì—†ëŠ” 3ê°€ì§€ ì´ìœ (Investment Killers)' ë¼ëŠ” ë³„ë„ í•­ëª©ì„ êµ¬ì„±í•˜ì‹­ì‹œì˜¤.

ê·¸ë¦¬ê³  ê° Killer ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì–´ë–»ê²Œ ë°©ì–´í•˜ê±°ë‚˜ ì™„í™”í•  ìˆ˜ ìˆëŠ”ì§€(Mitigation Plan) ë…¼ë¦¬ì ìœ¼ë¡œ ë°˜ë°•í•˜ë©°, ê·¸ëŸ¼ì—ë„ íˆ¬ìê°€ ìœ íš¨í•¨ì„ ì¦ëª…í•˜ì‹­ì‹œì˜¤.

5. ê°€ì„¤ì€ 'ê²€ì¦ ê°€ëŠ¥í•œ ì§ˆë¬¸'ìœ¼ë¡œ ì „í™˜ëœë‹¤.

"(ì •ë³´ ì—†ìŒ)"ì€ ê¸ˆì§€ì–´ì…ë‹ˆë‹¤. ëŒ€ì‹  "ëŒ€í‘œì´ì‚¬ì˜ ê¸€ë¡œë²Œ ì‚¬ì—…ê°œë°œ ì—­ëŸ‰ì€ KOICA ì‚¬ì—… ì„ ì • ì´ë ¥ìœ¼ë¡œ ì¼ë¶€ ì¦ëª…ë˜ì—ˆìœ¼ë‚˜, ë¶ë¯¸/ìœ ëŸ½ ì‹œì¥ ì§„ì¶œì„ ìœ„í•œ êµ¬ì²´ì ì¸ ë„¤íŠ¸ì›Œí¬ì™€ ì‹¤í–‰ë ¥ì€ ì‹¤ì‚¬ë¥¼ í†µí•´ 'OOê¸°ì—…ê³¼ì˜ íŒŒíŠ¸ë„ˆì‹­ ì²´ê²° ê²½í—˜', 'í•´ì™¸ ë§¤ì¶œ ë°œìƒ ì´ë ¥' ë“±ì„ í†µí•´ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•¨" ê³¼ ê°™ì´, ê²€ì¦í•´ì•¼ í•  êµ¬ì²´ì ì¸ ì§ˆë¬¸ê³¼ ì§€í‘œë¥¼ ì œì‹œí•˜ì‹­ì‹œì˜¤.

6. ì„íŒ©íŠ¸ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì˜ 'í•´ì(Moat)'ê°€ ëœë‹¤ (Impact as a Moat).

"í”Œë¼ìŠ¤í‹±ì„ ì¤„ì—¬ì„œ ì°©í•˜ë‹¤"ëŠ” ë¶„ì„ì€ ê±°ë¶€í•©ë‹ˆë‹¤. "ë™ì‚¬ì˜ ì¹œí™˜ê²½ ë¦¬í•„ ì†”ë£¨ì…˜ì´ ì°½ì¶œí•˜ëŠ” 'ìì› ì ˆê°' ë° 'íƒ„ì†Œ ë°°ì¶œê¶Œ'ì´ë¼ëŠ” ì„íŒ©íŠ¸ ìì‚°ì€, í–¥í›„ íƒ„ì†Œì„¸ ë“± í™˜ê²½ ê·œì œ ê°•í™” ì‹œ ê²½ìŸì‚¬ ëŒ€ë¹„ ì••ë„ì ì¸ ë¹„ìš© ìš°ìœ„ë¥¼ ì œê³µí•˜ëŠ” í•µì‹¬ì ì¸ ê²½ì œì  í•´ìë¡œ ì‘ìš©í•  ê²ƒ"ì²˜ëŸ¼, ì„íŒ©íŠ¸ê°€ ì–´ë–»ê²Œ ì§€ì†ê°€ëŠ¥í•œ ê²½ìŸìš°ìœ„ì™€ ì¬ë¬´ì  ì„±ê³¼ë¡œ ì§ê²°ë˜ëŠ”ì§€ë¥¼ ì¦ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

SDGsì™€ IRIS+ëŠ” ì´ 'ì„íŒ©íŠ¸-ì¬ë¬´ ì—°ê²°ê³ ë¦¬'ë¥¼ ì¦ëª…í•˜ëŠ” ë°ì´í„° ê·¼ê±°ë¡œë§Œ í™œìš©í•˜ì‹­ì‹œì˜¤.

7. ê²½ìŸ ë¶„ì„ì€ 'ì „ì¥(Battlefield)'ì„ ê·¸ë¦¬ëŠ” ê²ƒì´ë‹¤.

ê²½ìŸì‚¬ë¥¼ ë‚˜ì—´í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ê²½ìŸ êµ¬ë„(Positioning Map)ë¥¼ í†µí•´ **'ìš°ë¦¬ê°€ ì‹¸ì›Œ ì´ê¸¸ ìˆ˜ ìˆëŠ” ì „ì¥'**ì„ ëª…í™•íˆ ì •ì˜í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "ê²½ìŸì‚¬ë“¤ì´ ì™„ì œí’ˆ ì‹œì¥ì—ì„œ ë†’ì€ ë§ˆì¼€íŒ… ë¹„ìš©ìœ¼ë¡œ ê²½ìŸí•  ë•Œ, ìš°ë¦¬ëŠ” ë§ˆì§„ìœ¨ì´ ë†’ì€ 'ì›ì²œì†Œì¬' ì‹œì¥ì„ ë¬´í˜ˆì…ì„±í•˜ì—¬ ì „ì¥ì˜ ê·œì¹™ ìì²´ë¥¼ ë°”ê¿€ ê²ƒì…ë‹ˆë‹¤.")

8. ì„±ì¥ ì§€ì›ì€ '100ì¼ ê³„íš(100-Day Plan)'ìœ¼ë¡œ ì œì‹œí•œë‹¤.

'ê²½ì˜ ìë¬¸', 'ë„¤íŠ¸ì›Œí‚¹' ê°™ì€ ì¶”ìƒì ì¸ ì§€ì› ì „ëµì„ ì§€ì–‘í•©ë‹ˆë‹¤. íˆ¬ì ì§í›„ 100ì¼ ì•ˆì— ë‹¬ì„±í•  êµ¬ì²´ì ì¸ ëª©í‘œ 3~5ê°€ì§€ë¥¼ ì œì‹œí•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "100ì¼ ë‚´ ëª©í‘œ: 1) ìœ í•œí‚´ë²Œë¦¬, ì•„ëª¨ë ˆí¼ì‹œí”½ ë“± ì „ëµì  íŒŒíŠ¸ë„ˆì‚¬ì™€ ìµœì†Œ 3íšŒ ì´ìƒ ë¯¸íŒ… ì£¼ì„ , 2) TIPS ì¶”ì²œì„ ìœ„í•œ ê¸°ìˆ ì‚¬ì—…ê³„íšì„œ(TIPS) ì´ˆì•ˆ ì™„ì„±, 3) í›„ì† íˆ¬ì ìœ ì¹˜ë¥¼ ìœ„í•œ VC ë¦¬ìŠ¤íŠ¸ì—… ë° IR ìë£Œ ê³ ë„í™” ì™„ë£Œ")

9. ì¬ë¬´ ë¶„ì„ì€ 'ì‹œë‚˜ë¦¬ì˜¤'ì™€ 'ë¯¼ê°ë„'ë¥¼ ë³´ì—¬ì¤€ë‹¤.

'ì 'ì´ ì•„ë‹Œ 'ë²”ìœ„'ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•˜ì‹­ì‹œì˜¤. Base(ê¸°ë³¸), Best(ìµœìƒ), Worst(ìµœì•…) ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¬ë¬´ ì¶”ì •ê³¼ ì˜ˆìƒ ìˆ˜ìµë¥ ì„ ì œì‹œí•˜ì—¬, íˆ¬ìì˜ ì ì¬ì  ë³€ë™ì„±ì„ ëª…í™•íˆ ë³´ì—¬ì¤˜ì•¼ í•©ë‹ˆë‹¤.

ì†ìµì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” í•µì‹¬ ë³€ìˆ˜(Key Driver)ê°€ ë¬´ì—‡ì¸ì§€ ë°íˆê³ , í•´ë‹¹ ë³€ìˆ˜ì˜ ë³€ë™ì— ë”°ë¼ IRR, Multipleì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ì— ëŒ€í•œ 'ë¯¼ê°ë„ ë¶„ì„(Sensitivity Analysis)' ê²°ê³¼ë¥¼ ì„œìˆ í•˜ì‹­ì‹œì˜¤.

10. ì¢…í•© ê²°ë¡ ì€ 'íˆ¬ì ì§‘í–‰'ì„ ëª…ë ¹í•˜ëŠ” ê²ƒì´ë‹¤.

"íˆ¬ìë¥¼ ê¸ì •ì ìœ¼ë¡œ ê²€í† í•¨" ê°™ì€ ë¯¸ì˜¨ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "ìœ„ì™€ ê°™ì€ ë…¼ê±°ì— ê¸°ë°˜í•˜ì—¬, ë³¸ ì¡°í•©ì€ ë†ì—…íšŒì‚¬ë²•ì¸ ë¨¸ì‰¬ì•¤ì— ë³´í†µì£¼ OOOì›ì„ íˆ¬ìí•˜ëŠ” ì•ˆê±´ì„ 'ì§‘í–‰'í•  ê²ƒì„ ê°•ë ¥íˆ ì œì•ˆí•©ë‹ˆë‹¤." ì™€ ê°™ì´, í™•ì‹ ì— ì°¬ ì–´ì¡°ë¡œ ëª…í™•í•œ ì˜ì‚¬ê²°ì •ì„ ì´‰êµ¬í•˜ë©° ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.

ë³´ê³ ì„œ êµ¬ì¡° (Report Structure)
ì•„ë˜ì˜ ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì¤€ìˆ˜í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

Markdown

# Executive Summary

## 1. íˆ¬ì ê°œìš”
### 1.1. ê¸°ì—… ê°œìš”
### 1.2. íˆ¬ì ì¡°ê±´
### 1.3. ì†ìµ ì¶”ì • ë° ìˆ˜ìµì„±

## 2. ê¸°ì—… í˜„í™©
### 2.1. ì¼ë°˜ í˜„í™©
### 2.2. ì—°í˜ ë° ì£¼ì£¼í˜„í™©
### 2.3. ì¡°ì§ ë° í•µì‹¬ êµ¬ì„±ì›

## 3. ì‹œì¥ ë¶„ì„
### 3.1. ì‹œì¥ í˜„í™©
### 3.2. ê²½ìŸì‚¬ ë¶„ì„

## 4. ì‚¬ì—… ë¶„ì„
### 4.1. ì‚¬ì—… ê°œìš”
### 4.2. í–¥í›„ ì „ëµ ë° ê³„íš

## 5. íˆ¬ì ì í•©ì„±ê³¼ ì„íŒ©íŠ¸
### 5.1. íˆ¬ì ì í•©ì„±
### 5.2. ì†Œì…œì„íŒ©íŠ¸
### 5.3. íˆ¬ìì‚¬ ì„±ì¥ì§€ì› ì „ëµ

## 6. ì†ìµ ì¶”ì • ë° ìˆ˜ìµì„± ë¶„ì„
### 6.1. ì†ìµ ì¶”ì •
### 6.2. ê¸°ì—…ê°€ì¹˜í‰ê°€ ë° ìˆ˜ìµì„± ë¶„ì„

## 7. ì¢…í•© ê²°ë¡ 
INPUT DATA (ì…ë ¥ ë°ì´í„°)
í•™ìŠµ ë°ì´í„°: {learning_context} (ë‹¹ì‹ ì˜ ê³¼ê±° ì„±ê³µ ë©”ëª¨. ì—¬ê¸°ì„œ ë°ì´í„° ê¸°ë°˜ì˜ í™•ì‹ , ëª…ë£Œí•œ ë…¼ì§€, ë¶„ì„ì˜ í‹€ì„ í•™ìŠµí•  ê²ƒ)

ë¶„ì„ ëŒ€ìƒ IR ìë£Œ: {ir_summary} (ìƒˆë¡œìš´ ë”œ ì •ë³´. ì´ ë‚´ìš©ì„ ë‹¹ì‹ ì˜ ë¶„ì„ í‹€ì— ë„£ì–´ ì¬êµ¬ì„±í•  ê²ƒ)

EXECUTION (ìµœì¢… ëª…ë ¹)
ìœ„ì˜ MISSIONê³¼ THE PARTNER'S DECALOGUEì— ë”°ë¼, ì£¼ì–´ì§„ ì…ë ¥ ë°ì´í„°ë¥¼ í™œìš©í•˜ê³  ëª…ì‹œëœ ë³´ê³ ì„œ êµ¬ì¡°ë¥¼ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ **{company_name}**ì— ëŒ€í•œ **'Investment Thesis Memo'**ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ë‹¹ì‹ ì˜ ë‚ ì¹´ë¡œìš´ ë¶„ì„ì„ ê¸°ëŒ€í•©ë‹ˆë‹¤. ì‹œì‘í•˜ì‹­ì‹œì˜¤.
"""
        
        print(f"ğŸ¤– Gemini API í˜¸ì¶œ ì¤‘...")
        
        # ì‚¬ìš©ìì˜ API í‚¤ë¡œ Gemini API ì„¤ì •
        genai.configure(api_key=api_key)
        
        # Gemini API í˜¸ì¶œ
        model = genai.GenerativeModel('gemini-2.0-flash-exp')
        response = model.generate_content(prompt)
        
        print(f"âœ… Gemini API ì‘ë‹µ ì™„ë£Œ")
        
        return response.text
        
    except Exception as e:
        raise Exception(f"íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")

async def distribute_results(report_data: dict):
    """ê²°ê³¼ë¥¼ ì—¬ëŸ¬ ì±„ë„ë¡œ ì „ë‹¬"""
    try:
        print(f"ğŸ“¤ ê²°ê³¼ ë°°í¬ ì‹œì‘: {report_data['company_name']}")
        
        # 1. Airtableì— ì €ì¥
        if os.getenv("AIRTABLE_API_KEY") and os.getenv("AIRTABLE_BASE_ID"):
            try:
                await save_to_airtable(report_data)
                print("âœ… Airtable ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Airtable ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # 2. ì´ë©”ì¼ ë°œì†¡
        if os.getenv("NOTIFICATION_EMAIL"):
            try:
                await send_email_report(report_data)
                print("âœ… ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
        
        # 3. ì”ë”” ì•Œë¦¼
        if os.getenv("JANDI_WEBHOOK_URL"):
            try:
                await send_jandi_notification(report_data)
                print("âœ… ì”ë”” ì•Œë¦¼ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì”ë”” ì•Œë¦¼ ì‹¤íŒ¨: {e}")
        
        print(f"ğŸ“¤ ê²°ê³¼ ë°°í¬ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ ê²°ê³¼ ë°°í¬ ì¤‘ ì˜¤ë¥˜: {e}")

async def save_to_airtable(report_data: dict):
    """Airtableì— ê²°ê³¼ ì €ì¥"""
    airtable_url = f"https://api.airtable.com/v0/{os.getenv('AIRTABLE_BASE_ID')}/{os.getenv('AIRTABLE_TABLE_NAME', 'IRë¶„ì„ê²°ê³¼')}"
    
    headers = {
        "Authorization": f"Bearer {os.getenv('AIRTABLE_API_KEY')}",
        "Content-Type": "application/json"
    }
    
    data = {
        "fields": {
            "íšŒì‚¬ëª…": report_data["company_name"],
            "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ": report_data["investment_report"][:50000],  # Airtable ê¸¸ì´ ì œí•œ
            "ë¶„ì„ì¼ì‹œ": report_data["analysis_date"],
            "IR_URL": report_data["source_url"],
            "ìš”ì²­ì": report_data.get("requester", "Unknown")
        }
    }
    
    response = requests.post(airtable_url, headers=headers, json=data)
    response.raise_for_status()
    return response.json()

async def send_email_report(report_data: dict):
    """ì´ë©”ì¼ë¡œ ë³´ê³ ì„œ ë°œì†¡"""
    import smtplib
    from email.mime.text import MIMEText
    from email.mime.multipart import MIMEMultipart
    
    msg = MIMEMultipart()
    msg['From'] = os.getenv('SMTP_FROM_EMAIL')
    msg['To'] = os.getenv('NOTIFICATION_EMAIL')
    msg['Subject'] = f"ğŸ“Š íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ: {report_data['company_name']}"
    
    # HTML í˜•íƒœë¡œ ë³´ê³ ì„œ ì „ì†¡
    html_body = f"""
    <html>
    <body>
        <h2>ğŸ¢ íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ</h2>
        <h3>íšŒì‚¬ëª…: {report_data['company_name']}</h3>
        <p><strong>ë¶„ì„ì¼ì‹œ:</strong> {report_data['analysis_date']}</p>
        <p><strong>IR ìë£Œ:</strong> <a href="{report_data['source_url']}">{report_data['source_url']}</a></p>
        
        <hr>
        <div style="white-space: pre-wrap; font-family: Arial, sans-serif;">
        {report_data['investment_report'][:10000]}
        </div>
        
        {"<p><em>... ì „ì²´ ë³´ê³ ì„œëŠ” Airtableì—ì„œ í™•ì¸í•˜ì„¸ìš”.</em></p>" if len(report_data['investment_report']) > 10000 else ""}
    </body>
    </html>
    """
    
    msg.attach(MIMEText(html_body, 'html', 'utf-8'))
    
    # SMTP ì„œë²„ ì—°ê²° ë° ë°œì†¡
    server = smtplib.SMTP(os.getenv('SMTP_SERVER', 'smtp.gmail.com'), int(os.getenv('SMTP_PORT', '587')))
    server.starttls()
    server.login(os.getenv('SMTP_FROM_EMAIL'), os.getenv('SMTP_PASSWORD'))
    
    text = msg.as_string()
    server.sendmail(os.getenv('SMTP_FROM_EMAIL'), os.getenv('NOTIFICATION_EMAIL'), text)
    server.quit()

async def send_jandi_notification(report_data: dict):
    """ì”ë””ë¡œ ì™„ë£Œ ì•Œë¦¼"""
    webhook_url = os.getenv('JANDI_WEBHOOK_URL')
    
    payload = {
        "body": f"ğŸ“Š íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ!\n\n"
                f"ğŸ¢ íšŒì‚¬ëª…: {report_data['company_name']}\n"
                f"ğŸ“… ë¶„ì„ì¼ì‹œ: {report_data['analysis_date']}\n"
                f"ğŸ“ IR ìë£Œ: {report_data['source_url']}\n\n"
                f"ìƒì„¸ ë³´ê³ ì„œëŠ” Airtable ë˜ëŠ” ì´ë©”ì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”.",
        "connectColor": "#00D2BF",
        "connectInfo": [{
            "title": "íˆ¬ìì‹¬ì‚¬ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ",
            "description": f"{report_data['company_name']} ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        }]
    }
    
    response = requests.post(webhook_url, json=payload)
    response.raise_for_status()

def extract_company_name(text: str) -> str:
    """í…ìŠ¤íŠ¸ì—ì„œ íšŒì‚¬ëª… ì¶”ì¶œ"""
    # IRë¶„ì„, ë¶„ì„ ë“±ì˜ í‚¤ì›Œë“œ ì œê±° í›„ ì²« ë²ˆì§¸ ë‹¨ì–´ë¥¼ íšŒì‚¬ëª…ìœ¼ë¡œ ì‚¬ìš©
    clean_text = re.sub(r'IRë¶„ì„|ë¶„ì„|ìš”ì²­|ë¶€íƒ', '', text).strip()
    words = clean_text.split()
    
    for word in words:
        # URLì´ ì•„ë‹Œ ì²« ë²ˆì§¸ ë‹¨ì–´ë¥¼ íšŒì‚¬ëª…ìœ¼ë¡œ ì‚¬ìš©
        if not word.startswith('http'):
            return word
    
    return "ë¶„ì„ëŒ€ìƒê¸°ì—…"

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)